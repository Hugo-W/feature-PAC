{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate main figures\n",
    "\n",
    "This notebook generates the main figures of the article \"The Structure and Statistics of Language jointly shape Cross-frequency Dynamics during Spoken Language Comprehension\", H. Weissbart & AE. Martin.\n",
    "\n",
    "The following code rely on the Source Data accompnaying the article. The Source Data is available from the the figshare repository: https://doi.org/10.6084/m9.figshare.16668207\n",
    "\n",
    "## Content\n",
    "\n",
    "1. [Figure 2](#Figure-2)\n",
    "2. [Figure 3](#Figure-3)\n",
    "3. [Figure 4](#Figure-4)\n",
    "4. [Figure 5](#Figure-5)\n",
    "\n",
    "__Note__\n",
    "\n",
    "> Figure 1 is a schematic representation of the analysis pipeline and is not generated by the present notebook, however we supply another notebook to generate most of the panels of that figure.\n",
    "> Figure 6 of the article is generated with simulations and is not included in the present notebook, however we supply another notebook to generate the simulations and the accompanying figure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries\n",
    "\n",
    "Libraries and parameters used in the notebook. We will also add the code from `audiobook` to the Python path to be able to use the functions from the package.\n",
    "\n",
    "We assume that all required libraries are installed (this include the `pyeeg` package)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hugwei\\Desktop\\feature-PAC\\audiobook\\text.py:170: SyntaxWarning: invalid escape sequence '\\w'\n",
      "  wordlvl = wordlvl[wordlvl.token.str.contains('\\w')].reset_index() # new line of code: does it break the code for WF??!\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../audiobook')\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from audiobook.utils import extract_story_parts_data, STORIES, DATA_PATH, subjects, STIM_PATH\n",
    "from audiobook.features import get_acoustic_envelope, get_wordlevel_aligned\n",
    "from matplotlib import font_manager\n",
    "import pandas as pd \n",
    "\n",
    "# Figure parameters\n",
    "plt.style.use('default')\n",
    "plt.rcParams['figure.figsize'] = [7.2, 5.4]\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "plt.rcParams['font.family'] = 'sans'\n",
    "plt.rcParams['font.sans-serif'] = 'Helvetica'\n",
    "plt.rcParams['font.size'] = 7\n",
    "plt.rcParams['pdf.fonttype'] = 42\n",
    "plt.rcParams['savefig.transparent'] = True\n",
    "plt.rcParams['savefig.bbox'] = 'tight'\n",
    "plt.rcParams['savefig.dpi'] = 300\n",
    "\n",
    "\n",
    "## Colors\n",
    "featsets = [['wordonsets'],\n",
    "            ['wordonsets', 'depth', 'close'],\n",
    "            ['wordonsets', 'surprisal', 'entropy'],\n",
    "            ['wordonsets', 'surprisal', 'entropy', 'depth', 'close']]\n",
    "\n",
    "colors = {'wordonsets': (0.3,)*3}\n",
    "for k in featsets:\n",
    "    key = '_'.join(k)\n",
    "    is_predict = any([f in key for f in ['surprisal', 'wordfrequency']])\n",
    "    is_syntax = any([f in key for f in ['open', 'depth', 'close']])\n",
    "    if is_predict and not is_syntax:\n",
    "        if 'entropy' in key:\n",
    "            colors[key] = sns.blend_palette(['purple', 'seagreen', 'orange'], n_colors=5)[2]\n",
    "        else:\n",
    "            colors[key] = sns.blend_palette(['purple', 'seagreen', 'orange'], n_colors=5)[3]\n",
    "    if is_syntax and not is_predict:\n",
    "        colors[key] = sns.blend_palette(['purple', 'seagreen', 'orange'], n_colors=5)[0]\n",
    "    if is_syntax and is_predict:\n",
    "        colors[key] = sns.blend_palette(['purple', 'seagreen', 'orange'], n_colors=5)[-1]\n",
    "\n",
    "\n",
    "colors = {'wordonsets': (0.3,)*3}\n",
    "for k in featsets:\n",
    "    key = '_'.join(k)\n",
    "    is_predict = any([f in key for f in ['surprisal', 'wordfrequency']])\n",
    "    is_syntax = any([f in key for f in ['open', 'depth', 'close']])\n",
    "    if is_predict and not is_syntax:\n",
    "        if 'entropy' in key:\n",
    "            colors[key] = sns.blend_palette(['#7A4B9B', '#2AAD9D', 'orange'], n_colors=5)[2]\n",
    "        else:\n",
    "            colors[key] = sns.blend_palette(['#7A4B9B', '#2AAD9D', 'orange'], n_colors=5)[3]\n",
    "    if is_syntax and not is_predict:\n",
    "        colors[key] = sns.blend_palette(['#7A4B9B', '#2AAD9D', 'orange'], n_colors=5)[0]\n",
    "    if is_syntax and is_predict:\n",
    "        colors[key] = sns.blend_palette(['#7A4B9B', '#2AAD9D', 'orange'], n_colors=5)[-1]\n",
    "\n",
    "paper_fontsizes = {\n",
    "    'axes.labelsize': 7,\n",
    "    'axes.titlesize': 7,\n",
    "    'xtick.labelsize': 6,\n",
    "    'ytick.labelsize': 6,\n",
    "    'legend.fontsize': 7\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Figure 2\n",
    "\n",
    "This figures presents the summary of stimulus statistics and MEG spectra:\n",
    "\n",
    "- Power spectra of MEG\n",
    "- power spectra of audio fr vs nl\n",
    "- coherence\n",
    "- ITPC and Power modulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\hugwei\\documents\\pyeeg\\pyeeg\\simulate.py:246: SyntaxWarning: invalid escape sequence '\\ '\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.gridspec import GridSpec\n",
    "norm = mcolors.LogNorm(vmin=0.01, vmax=10)\n",
    "norm = mcolors.Normalize(vmin=0.01, vmax=10)\n",
    "from scipy.stats import ttest_1samp\n",
    "\n",
    "from pyeeg.vizu import topomap\n",
    "from tqdm.notebook import tqdm\n",
    "import glob\n",
    "import os\n",
    "from functools import reduce\n",
    "import mne\n",
    "from mne.stats import fdr_correction\n",
    "from audiobook.utils import SUBJECTS\n",
    "\n",
    "paper_fontsizes = {\n",
    "    'axes.labelsize': 7,\n",
    "    'axes.titlesize': 7,\n",
    "    'xtick.labelsize': 6,\n",
    "    'ytick.labelsize': 6,\n",
    "    'legend.fontsize': 7\n",
    "}\n",
    "\n",
    "from scipy.signal import welch\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats.distributions import t as tdist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'all_psds.npz'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Load relevant data\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Load power spectra\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mall_psds.npz\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m Pxx \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mkeys():\n",
      "File \u001b[1;32m~\\.conda\\envs\\hugo2\\Lib\\site-packages\\numpy\\lib\\npyio.py:427\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[0;32m    425\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    426\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 427\u001b[0m     fid \u001b[38;5;241m=\u001b[39m stack\u001b[38;5;241m.\u001b[39menter_context(\u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos_fspath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[0;32m    428\u001b[0m     own_fid \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    430\u001b[0m \u001b[38;5;66;03m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'all_psds.npz'"
     ]
    }
   ],
   "source": [
    "# Load relevant data\n",
    "# Load power spectra\n",
    "data = np.load('all_psds.npz', allow_pickle=True)\n",
    "Pxx = {}\n",
    "for k in data.keys():\n",
    "    Pxx[k] = data[k].item()\n",
    "data.close()\n",
    "\n",
    "# Load coherence data\n",
    "nl_cohs = []\n",
    "fr_cohs = []\n",
    "for f in glob.glob('./Data/coherence_nl_fr_sub*.npz'):\n",
    "    data = np.load(f)\n",
    "    nl_cohs.append(data['nl_coh'])\n",
    "    fr_cohs.append(data['fr_coh'])\n",
    "    data.close()\n",
    "# Need to fix the number of channels?\n",
    "nl_coh = np.mean(nl_cohs, 0)\n",
    "fr_coh = np.mean(fr_cohs, 0)\n",
    "\n",
    "# Fooof data\n",
    "df = pd.read_pickle('Data/Fooof/sensor_global_fooof_results.pkl')\n",
    "results = df.to_dict()\n",
    "\n",
    "# Parameters\n",
    "info_269 = mne.io.read_info(os.path.join(DATA_PATH, 'processed', 'sub-026', 'meg', 'audioBook-filtered-ICAed-raw.fif'))\n",
    "info_269 = mne.pick_info(info_269, mne.pick_types(info_269, meg=True, ref_meg=False))\n",
    "# Info with 267 channels:\n",
    "bads = ['MLT41', 'MRO52']\n",
    "info = mne.io.read_info(os.path.join(DATA_PATH, 'processed', 'sub-026', 'meg', 'audioBook-filtered-ICAed-raw.fif'))\n",
    "info = mne.pick_info(info, mne.pick_types(info, meg=True, ref_meg=False, exclude=bads))\n",
    "\n",
    "fs = 200\n",
    "nfreqbins = 1024\n",
    "freqs = np.fft.rfftfreq(nfreqbins, 1/fs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
